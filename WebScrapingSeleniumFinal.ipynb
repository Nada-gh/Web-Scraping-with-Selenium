{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.common.exceptions import NoSuchElementException \n",
    "from selenium.common.exceptions import WebDriverException\n",
    "from selenium.webdriver.common.keys import Keys #need to send keystrokes\n",
    "from datetime import datetime \n",
    "from datetime import timedelta\n",
    "from dateutil import parser\n",
    "import urllib\n",
    "import csv\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new instance of chrome \n",
    "browser = webdriver.Chrome(executable_path='C:/webdriver/chromedriver')\n",
    "\n",
    "start_date = '2019-02-21'\n",
    "start_date = parser.parse(start_date)\n",
    "\n",
    "SCROLL_PAUSE_TIME = 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('AirBnbOneDay.csv','w',encoding=\"utf-8\",newline='') as csvfile:\n",
    "    fieldnames = ['Date','Title','Price','Guests','Review','Review_stars']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    # how many days to loop through\n",
    "    for h in range(1,4):\n",
    "        Checkin_Date = start_date+timedelta(days=1)# check_in =19+1=20\n",
    "        Checkout_Date = start_date+timedelta(days=2)# check_out = 19+2=21\n",
    "        browser.get(\"https://www.airbnb.ca/s/homes?refinement_paths%5B%5D=%2Fhomes&query=New%20York&allow_override%5B%5D=&checkin=\"+Checkin_Date.strftime('%Y-%m-%d')+\"&checkout=\"+Checkout_Date.strftime('%Y-%m-%d')+\"&map_toggle=false\")\n",
    "        browser.maximize_window()\n",
    "        last_height = browser.execute_script(\"return document.body.scrollHeight\")# Get scroll height\n",
    "        then = time.time()\n",
    "        while True:\n",
    "            browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")# Scroll down to bottom\n",
    "            time.sleep(SCROLL_PAUSE_TIME) # Wait to load page\n",
    "            new_height = browser.execute_script(\"return document.body.scrollHeight\")# Calculate new scroll height and compare with last scroll height\n",
    "            if new_height == last_height or time.time()-then > 60:\n",
    "                break\n",
    "        last_height = new_height\n",
    "        cont = browser.find_element_by_xpath(\"//body[@class='with-new-header has-epcot-header']\")\n",
    "        prods = cont.find_elements_by_xpath(\"//meta[@itemprop='url']\")\n",
    "        links = [prod.get_attribute(\"content\") for prod in prods]  \n",
    "        for l in links: # 18 or 30 based on the num of the homes in the pag\n",
    "            driver = webdriver.Chrome(executable_path='C:/webdriver/chromedriver')\n",
    "            driver.get(\"https://\"+l)\n",
    "            tot = driver.find_element_by_xpath(\"//body[@class='with-new-header has-epcot-header']\")\n",
    "\n",
    "\n",
    "            try:\n",
    "                title = tot.find_element_by_class_name('_18hrqvin').text\n",
    "            except NoSuchElementException:\n",
    "                title = None\n",
    "\n",
    "            try:\n",
    "                price = tot.find_element_by_class_name('_doc79r').text\n",
    "            except NoSuchElementException:\n",
    "                price = None\n",
    "\n",
    "            try:\n",
    "                review_stars = tot.find_element_by_xpath(\"//button[@class='_ff6jfq']\").get_attribute(\"aria-label\")\n",
    "            except NoSuchElementException:\n",
    "                review_stars = None\n",
    "\n",
    "            try:\n",
    "                num_guests = tot.find_element_by_xpath(\"//span[@class='_1p3joamp']\").text\n",
    "            except NoSuchElementException:\n",
    "                num_guests = None\n",
    "\n",
    "            try:\n",
    "                review_txt = tot.find_element_by_xpath(\"//div[@id='reviews']\").text\n",
    "            except NoSuchElementException:\n",
    "                review_txt = None\n",
    "\n",
    "            writer.writerow({'Date' : Checkin_Date,\n",
    "                             'Title': title,\n",
    "                             'Price': price,\n",
    "                             'Guests': num_guests,\n",
    "                             'Review_stars': review_stars,\n",
    "                             'Review':review_txt})\n",
    "\n",
    "            time.sleep(10)\n",
    "            driver.close()\n",
    "            \n",
    "        #start_date = Checkin_Date\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "               # browser.find_element_by_xpath(\"//li[@class='_b8vexar']/a\").send_keys(\"\\n\") #send enter for links, buttons\n",
    "            #inputElement.send_keys(\"\\n\") #send enter for links, buttons\n",
    "         # Calculate new scroll height and compare with last scroll height\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
